Traceback (most recent call last):
  File "c:\Users\86189\ScaML-Experiment\results\Explicit_Solution_Example\experiment_run.py", line 49, in <module>
    trained_model=optimizer.train("results/Explicit_Solution_Example/model.pth",cycle=40,adam_every=500,lbfgs_every=10,metrics=["l2 relative error","mse"])
  File "c:\Users\86189\ScaML-Experiment\results\Explicit_Solution_Example\..\..\optimizers\Adam_LBFGS.py", line 33, in train
    loss_weights=torch.softmax(self.model._outputs_losses).detach().tolist()                           #use self adaptive loss weights
TypeError: softmax() received an invalid combination of arguments - got (method), but expected one of:
 * (Tensor input, int dim, torch.dtype dtype, *, Tensor out)
 * (Tensor input, name dim, *, torch.dtype dtype)